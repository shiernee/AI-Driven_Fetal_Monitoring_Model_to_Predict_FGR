{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiernee/AI-Driven_Fetal_Monitoring_Model_to_Predict_FGR/blob/main/basic_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDZhoPf-xu4G",
        "outputId": "1cf64c24-210c-4567-a960-4d3c88fafc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import uuid\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import logging\n",
        "from logging.handlers import RotatingFileHandler\n",
        "\n",
        "# Configure logging to write to a file\n",
        "log_formatter = logging.Formatter('%(asctime)s [%(levelname)s] - %(message)s')\n",
        "log_handler = logging.FileHandler('basic_cleaning_log.log')\n",
        "log_handler.setFormatter(log_formatter)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(log_handler)"
      ],
      "metadata": {
        "id": "COHOaeqWfkuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ante = pd.read_csv('/content/drive/MyDrive/SGA/Prev/fgr_df.csv')\n",
        "ante = ante.rename(columns={\n",
        "  \"A-wave\" : \"a_wave\",\n",
        "  \"AC\" : \"ac\",\n",
        "  \"AF Index\": \"af_idx\",\n",
        "  \"Amniotic fluid\" : \"af\",\n",
        "  \"BPD\" : 'bpd',\n",
        "  \"CM\" : 'cm',\n",
        "  \"Case number\" : 'case_no',\n",
        "  \"Cerebro-placental ratio\" : 'cpr',\n",
        "  \"Cervix length\" : 'cervix_len',\n",
        "  \"Cord\" : 'cord',\n",
        "  \"Ductus Venosus PI\" : \"dv_pi\",\n",
        "  \"EDF\" : \"edf\",\n",
        "  \"EFW (clinical)\" : \"efw_clinical\",\n",
        "  \"EFW centile\" : 'efw_centile',\n",
        "  \"Estimated fetal weight\" : 'efw',\n",
        "  \"Ethnic_group\" : 'ethnic',\n",
        "  \"Exam\" : 'exam',\n",
        "  \"Examination date\" : 'exam_date',\n",
        "  \"FL\": 'fl',\n",
        "  \"Fetal heart rate\": 'fetal_heart_rate',\n",
        "  \"Fetus\": 'fetus',\n",
        "  \"Funnelling\" : 'funneling',\n",
        "  \"GA (DAYS)\" : 'ga_days',\n",
        "  \"GA (WK)\" : 'ga_week',\n",
        "  \"HC\" : 'hc',\n",
        "  \"Hospital no.\" : 'hospital_no',\n",
        "  \"Humerus\": \"hl\",\n",
        "  \"MCA PI (2)\" : 'mca_pi',\n",
        "  \"MCA RI (2)\" : 'mca_ri',\n",
        "  \"Notch\" : 'notch',\n",
        "  \"PID\" : 'pid',\n",
        "  \"Placenta site\" : 'placenta_site',\n",
        "  \"Presentation\" : 'presentation',\n",
        "  \"RI left\" : 'ri_left',\n",
        "  \"RI right\": 'ri_right',\n",
        "  \"TAV\" : 'tav',\n",
        "  \"TCD\" : 'tcd',\n",
        "  \"UA PI\" : 'ua_pi',\n",
        "  \"UA RI\" : 'ua_ri',\n",
        "  \"Uterine artery PI  left\" :  'ua_pi_left',\n",
        "  \"Uterine artery PI  right\" : 'ua_pi_right',\n",
        "})\n",
        "ante.info()"
      ],
      "metadata": {
        "id": "kivU645xfnOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_hospital_no(df: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Clean the hospital_no, and assign missing hospital_no with unique identifier\n",
        "  Args:\n",
        "    df (pd.DataFrame): original input DataFrame\n",
        "  Return:\n",
        "    df (pd.DataFrame): modified output DataFrame\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Drop entries with no hospital no\n",
        "    n = df[df['hospital_no'].isna()]\n",
        "    df = df.drop(n.index)\n",
        "\n",
        "    # Filter hospital no that contains except 0 - 9 and .\n",
        "    nint = df[df['hospital_no'].str.contains(r'[^0-9.]', na=False)]\n",
        "\n",
        "    # Convert hospital no in int to str\n",
        "    inth = df.drop(nint.index)\n",
        "    inth['hospital_no'] = inth['hospital_no'].apply(lambda x: int(float(x)) if x.replace('.', '', 1).isdigit() else x).astype(str)\n",
        "\n",
        "    # Setting constant UUID to same patient\n",
        "    for id in n['pid'].unique():\n",
        "        n.loc[n['pid'] == id, 'hospital_no'] = '~' + str(uuid.uuid4())\n",
        "\n",
        "    # Merge all data\n",
        "    df = pd.concat([n, nint, inth])\n",
        "\n",
        "    # Optional: Assertion to check if 'hospital_no' column has no missing values\n",
        "    assert not df['hospital_no'].isna().any(), \"There are still missing values in the 'hospital_no' column.\"\n",
        "\n",
        "    # Logging information\n",
        "    logger.info(\"clean_hospital_no completed successfully.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at clean_hospital_no: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "ze5Hjs0TfsbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_start_date(df: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Correct and restore the start_date of pregnancy, also corrects the GA of the restored entries\n",
        "  Args:\n",
        "    df (pd.DataFrame): original input DataFrame\n",
        "  Return:\n",
        "    df (pd.DataFrame): modified output DataFrame\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Convert the total GA to days\n",
        "    df['ga'] = df['ga_week'] * 7 + df['ga_days']\n",
        "    # Calculate start date by subtracting examination date with gestational age\n",
        "    df['ga'] = pd.to_numeric(df['ga'], errors='coerce')\n",
        "    # Convert 'exam_date' to datetime if it's not already\n",
        "    df['exam_date'] = pd.to_datetime(df['exam_date'])\n",
        "    df['start_date'] = df['exam_date'] - pd.to_timedelta(df['ga'], unit='D')\n",
        "\n",
        "    # Split the data into entreis with start_date and without\n",
        "    withSD = df[df['start_date'].notna()]\n",
        "    nonSD = df[df['start_date'].isna()]\n",
        "\n",
        "    # Sort entries with hospital_no first, then with start_date\n",
        "    withSD = withSD.sort_values(['hospital_no', 'start_date']).reset_index(drop=True)\n",
        "\n",
        "    # Check current row hospital_no is same as next row hospital_no\n",
        "    # [If same hospital_no then False, will not assign new ID]\n",
        "    # Check current row pregnancy start_date is greater than next row pregnancy start_date\n",
        "    # [If same hospital_no and current row pregnancy start_date is within 7 days of next row start_date, treat it as same patient]\n",
        "    withSD['id'] = (withSD['hospital_no'] != withSD['hospital_no'].shift(1)) | (withSD['start_date'] > withSD['start_date'].shift(1) + pd.to_timedelta(7, unit='D'))\n",
        "    withSD['id'] = np.cumsum(withSD['id'])\n",
        "\n",
        "    # Group the data by the ID then select the mode of start_date occurence for that particular ID and to replace all other start date\n",
        "    newSD = withSD.groupby('id')['start_date'].apply(lambda x: pd.Series.mode(x)[0]).to_dict()\n",
        "    withSD['start_date'] = withSD['id'].apply(lambda x: newSD.get(x))\n",
        "\n",
        "    # Assign id=0 to entries without start_date\n",
        "    nonSD['id'] = 0\n",
        "    nonSD['start_date'] = None\n",
        "\n",
        "    # Get entries with start_date that has the same hospital_no with entries without start_date\n",
        "    temp = withSD[withSD['hospital_no'].isin(nonSD['hospital_no'])]\n",
        "\n",
        "    hosNo1 = list(temp['hospital_no'])\n",
        "    startDate1 = list(temp['start_date'])\n",
        "    id1 = list(temp['id'])\n",
        "\n",
        "    hosNo2 = list(nonSD['hospital_no'])\n",
        "    startDate2 = list(nonSD['start_date'])\n",
        "    examDate2 = list(nonSD['exam_date'])\n",
        "    id2 = list(nonSD['id'])\n",
        "\n",
        "    # If entries without start_date have same hospital_no as entries with start_date\n",
        "    # Get the days difference between exam_date (without start_date) and start_date (with start_date)\n",
        "    # If days >= 0 and days <= 300, then assume they are the same patient, having same id and start_date\n",
        "    # Assign start_date to entries with same hospital_no if their examination duration since start_date is not more than 300 days\n",
        "    for i in range(len(hosNo2)):\n",
        "      for j in range(len(hosNo1)):\n",
        "        if hosNo2[i] == hosNo1[j]:\n",
        "          days = examDate2[i] - startDate1[j]\n",
        "          if days >= pd.to_timedelta(0, unit='D') and days <= pd.to_timedelta(300, unit='D'):\n",
        "            startDate2[i] = startDate1[j]\n",
        "            id2[i] = id1[j]\n",
        "\n",
        "    # Assign start_date and ID\n",
        "    nonSD['start_date'] = startDate2\n",
        "    nonSD['id'] = id2\n",
        "\n",
        "    # Get entries with recovered start_date\n",
        "    recoveredSD = nonSD[nonSD['id'] != 0]\n",
        "    nonSD = nonSD.drop(recoveredSD.index)\n",
        "\n",
        "    # Get all entries with start_date\n",
        "    # Dropped 15139 entries (140106 - 124967 = 15139)\n",
        "    df = pd.concat([withSD, recoveredSD]).reset_index(drop=True)\n",
        "    df = df.sort_values(['id', 'exam_date']).reset_index(drop=True)\n",
        "\n",
        "    # Restore/correct GA\n",
        "    df['ga'] = (df['exam_date'] - df['start_date']).dt.days\n",
        "\n",
        "    assert df['start_date'].notna().all(), \"Entries with NaN start_date should be corrected and restored.\"\n",
        "    assert not df['ga'].isna().any(), \"All entries should have a valid gestational age (ga).\"\n",
        "    assert (df['exam_date'] - df['start_date']).dt.days.equals(df['ga']), \"Restored GA should be consistent with the corrected start_date.\"\n",
        "\n",
        "    logger.info(\"restore_start_date completed successfully.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at restore_start_date: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "4XYKsVt9fv05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_singleton(df: pd.DataFrame):\n",
        "  try:\n",
        "    # Assertion to check if 'id' and 'fetus' columns exist in the DataFrame\n",
        "    assert 'id' in df.columns and 'fetus' in df.columns, \"The 'id' or 'fetus' column is missing in the DataFrame.\"\n",
        "\n",
        "    new_fetus = df.groupby(['id'])['fetus'].max()\n",
        "    df['fetus_no'] = df[\"id\"].apply(lambda x: new_fetus.get(x))\n",
        "    df = df[df['fetus_no'] == 1.0]\n",
        "\n",
        "    # Assertion to check if 'fetus_no' column has no missing values\n",
        "    assert not df['fetus_no'].isna().any(), \"There are still missing values in the 'fetus_no' column.\"\n",
        "\n",
        "    # Logging information\n",
        "    logger.info(\"obtain_singleton completed successfully.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at obtain_singleton: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "CD8k075dfyBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_bpd_ac_hc_fl(df):\n",
        "  try:\n",
        "    df['fl'] = np.where(df['fl'].isna(), df['ac'] * 0.22, df['fl'])\n",
        "    df['bpd'] = np.where(df['bpd'].isna(), df['hc'] * 78 / (89 * math.pi), df['bpd'])\n",
        "    df['fl'] = np.where(df['fl'].isna(), df['bpd'] * 0.79, df['fl'])\n",
        "\n",
        "    df['ac'] = np.where(df['ac'].isna(), df['fl'] / 0.22, df['ac'])\n",
        "    df['bpd'] = np.where(df['bpd'].isna(), df['fl'] / 0.79, df['bpd'])\n",
        "    df['hc'] = np.where(df['hc'].isna(), df['bpd'] * (89 * math.pi) / 78, df['hc'])\n",
        "\n",
        "    logger.info(\"restore_bpd_ac_hc_fl completed successfully.\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at restore_bpd_ac_hc_fl: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "a6bV6on2fzKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_EFW(df):\n",
        "  \"\"\"\n",
        "  Compute Estimated Fetal Weight (EFW)\n",
        "  Args:\n",
        "    df (pd.DataFrame): original input DataFrame\n",
        "  Return:\n",
        "    df (pd.DataFrame): modified output DataFrame\n",
        "  \"\"\"\n",
        "  # Formula to compute EFW\n",
        "  # If BPD, AC, FL and HC is not NA, then calculate EFW using these values\n",
        "  # Else use the predefined EFW\n",
        "  try:\n",
        "    df['efw'] = np.where(\n",
        "      df[['bpd', 'ac', 'fl', 'hc']].notna().all(1),\n",
        "      round(10 ** (1.3596 +\n",
        "      0.0064 * df['hc']/10 +\n",
        "      0.0424 * df['ac']/10 +\n",
        "      0.174 * df['fl']/10 +\n",
        "      0.00061 * df['bpd']/10 * df['ac']/10 -\n",
        "      0.00386 * df['ac']/10 * df['fl']/10)),\n",
        "      np.where(\n",
        "        isinstance(df['efw'], float) or isinstance(df['efw'], int),\n",
        "        df['efw'],\n",
        "        np.nan\n",
        "      )\n",
        "    )\n",
        "    logger.info(\"compute_EFW completed successfully.\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at compute_EFW: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "yItSoGb0f1Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_CPR(df):\n",
        "  \"\"\"\n",
        "  Compute Cerebellar-Placenta Ratio\n",
        "  Args:\n",
        "    df (pd.DataFrame): original input DataFrame\n",
        "  Return:\n",
        "    df (pd.DataFrame): modified output DataFrame\n",
        "  \"\"\"\n",
        "  # Compute CPR\n",
        "  df['cpr'] = np.where(df[['mca_pi', 'ua_pi']].notna().all(1), df['mca_pi']/df['ua_pi'], df['cpr'])\n",
        "  logger.info(\"compute_CPR completed successfully.\")\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "niN6k7-vf2xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.ncbi.nlm.nih.gov/books/NBK441881/\n",
        "# A normal amniotic fluid index is 5 cm to 25 cm using the standard assessment method. Less than 5 cm is considered oligohydramnios, and greater than 25  cm is considered polyhydramnios.\n",
        "\n",
        "def compute_AFI(df):\n",
        "  df['af'] = np.where(df['af_idx'].notna(),\n",
        "    pd.cut(df['af_idx'], bins = [0, 5, 25, np.inf], labels = ['oligohydramnios', 'normal', 'polyhydramnios']),\n",
        "    df['af'])\n",
        "  df.replace({'anhydramnios' : 'oligohydramnios', 'reduced' : 'oligohydramnios', 'increased' : 'polyhydramnios'}, inplace = True)\n",
        "\n",
        "  logger.info(\"compute_AFI completed successfully.\")\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "jbase5gLf7V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_EFW_centile(df, centile_df):\n",
        "  try:\n",
        "    centile_df = centile_df.rename(columns={'GA' : 'ga'})\n",
        "    centile_df['ga'] = centile_df['ga'].astype(int)\n",
        "\n",
        "    df = pd.merge(df, centile_df, on = 'ga', how = 'left')\n",
        "    refCentile = list(centile_df.columns)[1:]\n",
        "    ranges = df[[2.5, 5, 10, 25, 50, 75, 90, 95, 97.5]].values.tolist()\n",
        "    efw = df['efw'].values.tolist()\n",
        "    centile = []\n",
        "\n",
        "    for i in range(len(efw)):\n",
        "      if efw[i] >= ranges[i][0] and efw[i] <= ranges[i][-1]:\n",
        "        for j in range(len(ranges[i])):\n",
        "          if efw[i] == ranges[i][j]:\n",
        "            centile.append(refCentile[j])\n",
        "            break\n",
        "          if efw[i] < ranges[i][j]:\n",
        "            centile.append(refCentile[j] - (refCentile[j] - refCentile[j - 1]) * (ranges[i][j] - efw[i]) / (ranges[i][j] - ranges[i][j - 1]))\n",
        "            break\n",
        "      else:\n",
        "        centile.append(0)\n",
        "\n",
        "    df['efw_centile'] = centile\n",
        "    df.drop(df[df['efw_centile'] == 0].index, inplace = True)\n",
        "    df['cur_sga'] = df['efw_centile'] <= 10\n",
        "\n",
        "    assert not df['efw_centile'].isna().any(), \"There are null values in the 'efw_centile' column after restoration.\"\n",
        "    logger.info(\"compute_EFW_centile completed successfully.\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at compute_EFW_centile: {str(e)}\")\n",
        "    raise\n",
        "\n"
      ],
      "metadata": {
        "id": "roqf0REif-Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_antenatal_data(df):\n",
        "  \"\"\"\n",
        "  Clean up antenatal data\n",
        "  Args:\n",
        "    df (pd.DataFrame): original input DataFrame\n",
        "  Return:\n",
        "    df (pd.DataFrame): cleaned output DataFrame\n",
        "  \"\"\"\n",
        "  # Steps to clean antenatal data\n",
        "  df = clean_hospital_no(df)\n",
        "  df = restore_start_date(df)\n",
        "  df = obtain_singleton(df)\n",
        "  df = restore_bpd_ac_hc_fl(df)\n",
        "  df = compute_EFW(df)\n",
        "  df = compute_CPR(df)\n",
        "  df = compute_AFI(df)\n",
        "  centile_df = pd.read_excel('/content/drive/MyDrive/SGA/Prev/EFW centile.xlsx')\n",
        "  df = compute_EFW_centile(df, centile_df)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "VDRQf3Q5gAbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post = pd.read_csv('/content/drive/MyDrive/SGA/Years/IUGR_Studies.csv')\n",
        "post = post.rename(columns={\n",
        "  'Hospital No' : 'hospital_no', # Cleaned\n",
        "  'Fetus No' : 'fetus_no_birth', # No need to clean since all same value of 1\n",
        "  \"Mother's Date of Birth (dd/mm/yy)\" : \"mother_dob\",\n",
        "  \"Mother's Age at Delivery (Yrs)\" : \"mother_age\",\n",
        "  \"Mother weight taken Date (dd/mm/yy)\" : \"mother_weight_taken_date\",\n",
        "  \"Mother Weight (kg) at first visit\" : \"mother_weight\",\n",
        "  \"Mother Height (cm)\" : \"mother_height\",\n",
        "  \"Mother Smoking (Yes = 1, No = 0]\" : \"smoking\",\n",
        "  \"Hypertension - Pregancy Induced or Essential [Nil = 0, PIH = 1, Essential HpT = 2]\" : \"hypertension\",\n",
        "  \"Diabetes - Gestational or Pregestational                                     [Nil=0, GDM=1, PRE-GDM=2]\": \"diabetes\",\n",
        "  \"Others (State)\" : \"other_disease\",\n",
        "  'Date of Delivery (dd/mm/yy)' : \"date_of_delivery\",\n",
        "  'Mode of Delivery [SVD=1, Forceps=2, Vacuum=3, LSCS=4,D&C=5, Breech delivery=6]': \"mode_of_delivery\",\n",
        "  'GA at birth (week)' : \"ga_birth_week\",\n",
        "  'GA at birth (day)' : \"ga_birth_day\",\n",
        "  'GA at birth (completed weeks + days = convert to decimal point, e.g. 24 weeks + 5 days \"= 24 +5/7\" = 24.71)': 'ga_birth',\n",
        "  'Baby Gender (F/M) (A=Ambigious)': 'gender',\n",
        "  'Birthweight (g) ' : 'birth_weight',\n",
        "  'Birth Length (cm)' : \"birth_length\",\n",
        "  'Head circumference (cm)' : 'hc_birth',\n",
        "  'Apgar Score (1min)' : 'apgar_1_min',\n",
        "  'Apgar Score (5min)' : 'apgar_5_min',\n",
        "  'Neonatal Outcome (Alive = 1/ Dead = 2)': 'neonatal',\n",
        "  'Admission to NICU/ PICU/ WARD [NICU/SCN=1, PICU=2, Ward=3, Maternity (Not admitted)=4,Mortuary=5]' : 'admission',\n",
        "  'Death Diagnosis (no death = 0,  yes = 1)' : 'death'\n",
        "})\n",
        "post.info()"
      ],
      "metadata": {
        "id": "1SS_pqnRgDxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_postnatal_data(df):\n",
        "  try:\n",
        "    # Remove weird data\n",
        "    df.replace(['1-Jan-1290', '20-Apr-20'], np.nan, inplace = True)\n",
        "    # Convert Hospital no. to str\n",
        "    df['hospital_no'] = df['hospital_no'].astype(str)\n",
        "    # Convert the total GA to days\n",
        "    df['ga_birth'] = df['ga_birth_week'] * 7 + df['ga_birth_day']\n",
        "    df['ga_birth'] = pd.to_numeric(df['ga_birth'], errors='coerce')\n",
        "    # Convert 'date_of_delivery' to datetime if it's not already\n",
        "    df['date_of_delivery'] = pd.to_datetime(df['date_of_delivery'])\n",
        "    # Calculate Start Date from Delivery Date\n",
        "    df['start_date_post'] = df['date_of_delivery'] - pd.to_timedelta(df['ga_birth'], unit = 'D')\n",
        "    # Remove dead fetus\n",
        "    df = df[(df['neonatal'] == 1) & (df['death'] == 0)]\n",
        "\n",
        "    assert not any(df['date_of_delivery'].isna()), \"There are missing values in the 'date_of_delivery' column after cleaning.\"\n",
        "    assert not any(df['ga_birth'].isna()), \"There are missing values in the 'ga_birth' column after cleaning.\"\n",
        "    assert not any(df['start_date_post'].isna()), \"There are missing values in the 'start_date_post' column after cleaning.\"\n",
        "\n",
        "    logger.info(\"compute_EFW_centile completed successfully.\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at clean_postnatal_data: {str(e)}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "fYhU5ZqggFLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_clean_ante_post(ante, post):\n",
        "  try:\n",
        "    df = pd.merge(ante, post, on = ['hospital_no'], how = 'left')\n",
        "    df = df[(df['start_date'] >= df['start_date_post'] - pd.DateOffset(days = 7)) & (df['start_date'] <= df['start_date_post'] + pd.DateOffset(days = 7))]\n",
        "    df['gender'].replace({'B' : 'M'}, inplace = True)\n",
        "    df['start_date'] = pd.to_datetime(df['start_date'])\n",
        "    df['mother_dob'] = pd.to_datetime(df['mother_dob'])\n",
        "\n",
        "    # Calculate 'mother_age_at_start_date'\n",
        "    df['mother_age_at_start_date'] = (\n",
        "      (df['start_date'].dt.month == df['mother_dob'].dt.month) &\n",
        "      (df['start_date'].dt.day < df['mother_dob'].dt.day)\n",
        "    ) | (df['start_date'].dt.month < df['mother_dob'].dt.month)\n",
        "    df['mother_age_at_start_date'] = df['start_date'].dt.year - df['mother_dob'].dt.year - df['mother_age_at_start_date']\n",
        "\n",
        "    logger.info(\"merge_clean_ante_post completed successfully.\")\n",
        "    return df\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"Error at merge_clean_ante_post: {str(e)}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "50JuLe3lgGSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_groundtruth(df):\n",
        "  gt = pd.read_csv('/content/drive/MyDrive/SGA/Ref_Centile/I21_BW.csv')\n",
        "  gt.columns = gt.columns.str.lower()\n",
        "  gt.rename(columns = {'ga' : 'ga_birth'}, inplace = True)\n",
        "  df = pd.merge(df, gt, on = ['ga_birth', 'gender'], how = 'left')\n",
        "  df['sga'] = df['birth_weight'] / 1000 <= df['p_10']\n",
        "  df['lbw'] = df['birth_weight'] / 1000 <= 2.5\n",
        "  df['status_change'] = df['cur_sga'] ^ df['sga']\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "j54M8IkKgHwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_ante = clean_antenatal_data(ante)\n",
        "cleaned_post = clean_postnatal_data(post)\n",
        "df = merge_clean_ante_post(cleaned_ante, cleaned_post)\n",
        "df = merge_groundtruth(df)"
      ],
      "metadata": {
        "id": "rwLOWTl7gNrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain neccessary cell and label encoding\n",
        "df = df[['a_wave', 'ac', 'af', 'bpd', 'cm', 'cpr', 'cervix_len', 'cord', 'dv_pi', 'edf', 'efw_centile', 'efw', 'fl', 'fetal_heart_rate', 'funneling', 'ga', 'hc', 'hl', 'id', 'mca_pi', 'mca_ri', 'notch', 'placenta_site', 'presentation', 'tcd', 'ua_pi', 'ua_ri', 'ua_pi_left', 'ua_pi_right', 'mother_age_at_start_date', 'mother_height', 'mother_weight', 'smoking', 'hypertension', 'diabetes', 'gender', 'sga', 'lbw', 'cur_sga', 'status_change', 'birth_weight']]\n",
        "#df.info()"
      ],
      "metadata": {
        "id": "kp3uJjRUgUdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri2 = df[df['ga'] < 182]\n",
        "tri3 = df[df['ga'] >= 182]\n",
        "tri2.dropna(thresh = len(tri2) * 0.4, axis = 1, inplace = True)\n",
        "tri3.dropna(thresh = len(tri3) * 0.4, axis = 1, inplace = True)\n",
        "tri2.info()\n",
        "tri3.info()"
      ],
      "metadata": {
        "id": "OWp5CmbQgVqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
